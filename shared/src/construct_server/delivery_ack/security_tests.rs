// ============================================================================
// Security Tests for Delivery ACK (Solution 1D - Privacy-First)
// ============================================================================
//
// These tests verify the security guarantees of the Delivery ACK system:
// 1. Hashing prevents plaintext ID leakage
// 2. Kafka logs contain ONLY hashes (no correlation possible)
// 3. Redis mappings expire automatically
// 4. Batching prevents timing correlation
// 5. Secret key requirement enforced
//
// ============================================================================

use crate::delivery_ack::*;
use crate::kafka::types::DeliveryAckEvent;
use construct_crypto::{compute_message_hash, compute_user_id_hash, verify_message_hash};
use serial_test::serial;

/// Test 1: Verify HMAC hashes are deterministic and collision-resistant
#[cfg(test)]
#[test]
fn test_hmac_deterministic_and_collision_resistant() {
    let secret = b"test_secret_key_32_bytes_long!!!";
    let message_id_1 = "550e8400-e29b-41d4-a716-446655440000";
    let message_id_2 = "550e8400-e29b-41d4-a716-446655440001"; // One digit different

    // Same input → same hash (deterministic)
    let hash1a = compute_message_hash(message_id_1, secret);
    let hash1b = compute_message_hash(message_id_1, secret);
    assert_eq!(hash1a, hash1b, "Hashing must be deterministic");

    // Different input → different hash (collision resistant)
    let hash2 = compute_message_hash(message_id_2, secret);
    assert_ne!(
        hash1a, hash2,
        "Similar messages must produce different hashes"
    );

    // Hash is 64 hex chars (32 bytes SHA256)
    assert_eq!(hash1a.len(), 64, "Hash must be 64 hex characters");
}

/// Test 2: Verify different secrets produce different hashes
#[cfg(test)]
#[test]
fn test_different_secrets_produce_different_hashes() {
    let secret1 = b"secret_key_number_1_32_bytes!!!!";
    let secret2 = b"secret_key_number_2_32_bytes!!!!";
    let message_id = "550e8400-e29b-41d4-a716-446655440000";

    let hash1 = compute_message_hash(message_id, secret1);
    let hash2 = compute_message_hash(message_id, secret2);

    assert_ne!(
        hash1, hash2,
        "Different secrets must produce different hashes"
    );
}

/// Test 3: Verify hash is one-way (cannot reverse engineer)
#[cfg(test)]
#[test]
fn test_hash_is_one_way() {
    let secret = b"test_secret_key_32_bytes_long!!!";
    let message_id = "550e8400-e29b-41d4-a716-446655440000";
    let hash = compute_message_hash(message_id, secret);

    // Hash should not contain any part of the message_id
    assert!(
        !hash.contains("550e8400"),
        "Hash must not contain plaintext ID"
    );
    assert!(!hash.contains("e29b"), "Hash must not contain plaintext ID");

    // Hash should be hex-encoded
    assert!(
        hash.chars().all(|c: char| c.is_ascii_hexdigit()),
        "Hash must be hex"
    );
}

/// Test 4: Verify user ID hashing works identically
#[cfg(test)]
#[test]
fn test_user_id_hashing() {
    let secret = b"test_secret_key_32_bytes_long!!!";
    let user_id = "user-550e8400-e29b-41d4-a716-446655440000";

    let hash = compute_user_id_hash(user_id, secret);

    // Same properties as message hash
    assert_eq!(hash.len(), 64, "User ID hash must be 64 hex characters");
    assert!(
        hash.chars().all(|c: char| c.is_ascii_hexdigit()),
        "Hash must be hex"
    );
    assert!(
        !hash.contains("550e8400"),
        "Hash must not contain plaintext ID"
    );
}

/// Test 5: Verify DeliveryAckEvent validates hash format
#[cfg(test)]
#[test]
fn test_delivery_ack_event_validation() {
    // Valid event (all hashes are 64 chars)
    let valid_event = DeliveryAckEvent::new(
        "msg-123".to_string(),
        "a".repeat(64), // Valid 64-char hash
        "b".repeat(64),
        "c".repeat(64),
    );
    assert!(
        valid_event.validate().is_ok(),
        "Valid event must pass validation"
    );

    // Invalid event (short hash)
    let invalid_event = DeliveryAckEvent {
        message_hash: "short_hash".to_string(), // Too short
        sender_id_hash: "b".repeat(64),
        recipient_id_hash: "c".repeat(64),
        delivered_at: 123456789,
        message_id: "msg-123".to_string(),
    };
    assert!(
        invalid_event.validate().is_err(),
        "Short hash must fail validation"
    );

    // Invalid event (non-hex hash)
    let invalid_event2 = DeliveryAckEvent {
        message_hash: "z".repeat(64), // Invalid hex
        sender_id_hash: "b".repeat(64),
        recipient_id_hash: "c".repeat(64),
        delivered_at: 123456789,
        message_id: "msg-123".to_string(),
    };
    // Note: validate() only checks length, not hex format
    // This is acceptable as Kafka deserialization will fail on invalid JSON
    assert!(
        invalid_event2.validate().is_ok(),
        "Hex validation happens at serialization layer"
    );
}

/// Test 6: Verify constant-time comparison prevents timing attacks
#[cfg(test)]
#[test]
fn test_constant_time_comparison() {
    let secret = b"test_secret_key_32_bytes_long!!!";
    let message_id = "550e8400-e29b-41d4-a716-446655440000";
    let correct_hash = compute_message_hash(message_id, secret);

    // Correct hash verifies
    assert!(
        verify_message_hash(message_id, &correct_hash, secret),
        "Correct hash must verify"
    );

    // Incorrect hash (first char different) does not verify
    let mut wrong_hash = correct_hash.clone();
    wrong_hash.replace_range(0..1, "f");
    assert!(
        !verify_message_hash(message_id, &wrong_hash, secret),
        "Incorrect hash must not verify"
    );

    // Completely wrong hash does not verify
    let fake_hash = "0".repeat(64);
    assert!(
        !verify_message_hash(message_id, &fake_hash, secret),
        "Fake hash must not verify"
    );
}

/// Test 7: Verify DeliveryAckConfig enforces secret key length
#[cfg(test)]
#[test]
#[serial]
fn test_config_enforces_key_length() {
    use std::env;

    // Clear env first
    unsafe {
        env::remove_var("DELIVERY_ACK_MODE");
        env::remove_var("DELIVERY_SECRET_KEY");
        env::remove_var("DELIVERY_ACK_ENABLE_BATCHING");
        env::remove_var("DELIVERY_ACK_BATCH_BUFFER_SECS");
    }

    // Valid key (32 bytes = 64 hex chars) - use a valid key with good entropy
    // This key has good diversity: 16 different hex characters
    let valid_key = "0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef";
    unsafe {
        env::set_var("DELIVERY_ACK_MODE", "postgres");
        env::set_var("DELIVERY_SECRET_KEY", valid_key);
    }
    let config = DeliveryAckConfig::from_env();
    assert!(config.is_ok(), "64-char hex key must be valid");
    assert_eq!(config.unwrap().secret_key.len(), 32, "Key must be 32 bytes");

    // Invalid key (too short)
    unsafe {
        env::set_var("DELIVERY_ACK_MODE", "postgres");
        env::set_var("DELIVERY_SECRET_KEY", "a".repeat(32)); // Only 16 bytes
    }
    let config = DeliveryAckConfig::from_env();
    assert!(config.is_err(), "Short key must be rejected");

    // Invalid key (too long)
    unsafe {
        env::set_var("DELIVERY_ACK_MODE", "postgres");
        env::set_var("DELIVERY_SECRET_KEY", "a".repeat(128)); // 64 bytes
    }
    let config = DeliveryAckConfig::from_env();
    assert!(config.is_err(), "Long key must be rejected");

    // Clean up
    unsafe {
        env::remove_var("DELIVERY_ACK_MODE");
        env::remove_var("DELIVERY_SECRET_KEY");
    }
}

/// Test 8: Verify disabled mode doesn't require secret key
#[cfg(test)]
#[test]
#[serial]
fn test_disabled_mode_no_secret_required() {
    use std::env;

    // Clear env first
    unsafe {
        env::remove_var("DELIVERY_ACK_MODE");
        env::remove_var("DELIVERY_SECRET_KEY");
        env::remove_var("DELIVERY_ACK_ENABLE_BATCHING");
        env::remove_var("DELIVERY_ACK_BATCH_BUFFER_SECS");
    }

    unsafe {
        env::set_var("DELIVERY_ACK_MODE", "disabled");
        env::remove_var("DELIVERY_SECRET_KEY");
    }

    let config = DeliveryAckConfig::from_env();
    assert!(config.is_ok(), "Disabled mode must not require secret key");
    assert_eq!(config.unwrap().mode, DeliveryAckMode::Disabled);

    // Clean up
    unsafe {
        env::remove_var("DELIVERY_ACK_MODE");
    }
}

/// Test 9: Verify generated keys are random and valid
#[cfg(test)]
#[test]
fn test_generated_keys_are_random() {
    let key1 = DeliveryAckConfig::generate_secret_key();
    let key2 = DeliveryAckConfig::generate_secret_key();

    // Keys are 64 hex chars
    assert_eq!(key1.len(), 64, "Generated key must be 64 hex chars");
    assert_eq!(key2.len(), 64, "Generated key must be 64 hex chars");

    // Keys are valid hex
    assert!(key1.chars().all(|c| c.is_ascii_hexdigit()));
    assert!(key2.chars().all(|c| c.is_ascii_hexdigit()));

    // Keys are different (randomness)
    assert_ne!(key1, key2, "Generated keys must be random");

    // Keys decode to 32 bytes
    let key1_bytes = hex::decode(&key1).unwrap();
    assert_eq!(key1_bytes.len(), 32, "Decoded key must be 32 bytes");
}

/// Test 10: Verify batching configuration
#[cfg(test)]
#[test]
#[serial]
fn test_batching_configuration() {
    use std::env;

    // Clear env first
    unsafe {
        env::remove_var("DELIVERY_ACK_MODE");
        env::remove_var("DELIVERY_SECRET_KEY");
        env::remove_var("DELIVERY_ACK_ENABLE_BATCHING");
        env::remove_var("DELIVERY_ACK_BATCH_BUFFER_SECS");
    }

    // Batching enabled by default
    // Use a valid key with good entropy (16 different hex characters)
    let valid_key = "0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef";
    unsafe {
        env::set_var("DELIVERY_ACK_MODE", "kafka");
        env::set_var("DELIVERY_SECRET_KEY", valid_key);
        env::remove_var("DELIVERY_ACK_ENABLE_BATCHING");
    }
    let config = DeliveryAckConfig::from_env().unwrap();
    assert!(
        config.enable_batching,
        "Batching must be enabled by default"
    );
    assert_eq!(
        config.batch_buffer_secs, 5,
        "Default buffer must be 5 seconds"
    );

    // Batching can be disabled
    // Use a valid key with good entropy (16 different hex characters)
    let valid_key = "0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef";
    unsafe {
        env::set_var("DELIVERY_ACK_MODE", "kafka");
        env::set_var("DELIVERY_SECRET_KEY", valid_key);
        env::set_var("DELIVERY_ACK_ENABLE_BATCHING", "false");
    }
    let config = DeliveryAckConfig::from_env().unwrap();
    assert!(!config.enable_batching, "Batching must be disableable");

    // Custom buffer time
    unsafe {
        env::set_var("DELIVERY_ACK_MODE", "kafka");
        env::set_var("DELIVERY_SECRET_KEY", valid_key);
        env::set_var("DELIVERY_ACK_ENABLE_BATCHING", "true");
        env::set_var("DELIVERY_ACK_BATCH_BUFFER_SECS", "10");
    }
    let config = DeliveryAckConfig::from_env().unwrap();
    assert_eq!(
        config.batch_buffer_secs, 10,
        "Custom buffer must be configurable"
    );

    // Clean up
    unsafe {
        env::remove_var("DELIVERY_ACK_MODE");
        env::remove_var("DELIVERY_SECRET_KEY");
        env::remove_var("DELIVERY_ACK_ENABLE_BATCHING");
        env::remove_var("DELIVERY_ACK_BATCH_BUFFER_SECS");
    }
}

// ============================================================================
// Integration Tests (require Redis + Kafka)
// ============================================================================

#[cfg(all(test, feature = "integration-tests"))]
mod integration_tests {
    use super::*;

    /// Integration test: Verify Redis ephemeral mappings expire
    #[tokio::test]
    #[ignore] // Requires Redis
    async fn test_redis_mapping_ttl() {
        // TODO: Implement when integration test infrastructure is ready
        // 1. Create KafkaDeliveryStorage with 1-second TTL
        // 2. Save a mapping
        // 3. Verify it exists immediately
        // 4. Wait 2 seconds
        // 5. Verify it expired
    }

    /// Integration test: Verify Kafka ACK events contain only hashes
    #[tokio::test]
    #[ignore] // Requires Kafka
    async fn test_kafka_events_contain_only_hashes() {
        // TODO: Implement when integration test infrastructure is ready
        // 1. Send DeliveryAckEvent to Kafka
        // 2. Consume event from Kafka
        // 3. Verify all fields are hashed
        // 4. Verify no plaintext IDs in event
    }

    /// Integration test: Verify batching randomizes order
    #[tokio::test]
    #[ignore] // Requires Kafka
    async fn test_batching_randomizes_order() {
        // TODO: Implement when integration test infrastructure is ready
        // 1. Create AckBatcher with batching enabled
        // 2. Enqueue 10 ACK events in order
        // 3. Flush batch
        // 4. Verify order was randomized (not sequential)
    }
}
