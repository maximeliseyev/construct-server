// ============================================================================
// Redis Streams Implementation Example
// ============================================================================
// 
// This file demonstrates how to implement Redis Streams methods for delivery queues.
// This is a reference implementation to be integrated into queue.rs
//
// Key Benefits:
// - Blocking read (0 commands when no messages)
// - Consumer groups for automatic distribution
// - Single XADD command (vs RPUSH + EXPIRE)
// - Automatic message acknowledgment
//
// ============================================================================

use anyhow::{Context, Result};
use redis::{AsyncCommands, cmd};
use std::collections::HashMap;

/// Stream message structure
#[derive(Debug, Clone)]
pub struct StreamMessage {
    pub id: String,
    pub fields: HashMap<String, Vec<u8>>,
}

impl StreamMessage {
    pub fn message_id(&self) -> Option<String> {
        self.fields.get("message_id")
            .and_then(|bytes| String::from_utf8(bytes.clone()).ok())
    }

    pub fn payload(&self) -> Option<&[u8]> {
        self.fields.get("payload").map(|v| v.as_slice())
    }
}

impl MessageQueue {
    /// Push message to delivery stream using XADD
    /// 
    /// Uses XADD with MAXLEN for automatic trimming:
    /// XADD stream_key MAXLEN ~ max_len * message_id payload message_bytes
    /// 
    /// Returns the stream message ID (e.g., "1234567890-0")
    pub async fn push_to_delivery_stream(
        &mut self,
        stream_key: &str,
        message_id: &str,
        message_bytes: &[u8],
        max_len: Option<usize>,
    ) -> Result<String> {
        let mut args = vec![stream_key];
        
        // Add MAXLEN for automatic trimming (approximately, using ~ for efficiency)
        if let Some(len) = max_len {
            args.push("MAXLEN");
            args.push("~"); // Approximate trimming (faster)
            args.push(&len.to_string());
        }
        
        // Use * for auto-generated ID (timestamp-sequence)
        args.push("*");
        
        // Add fields: message_id and payload
        args.push("message_id");
        args.push(message_id);
        args.push("payload");
        // Note: Redis commands accept bytes, but we need to encode them
        // For binary data, we can use base64 or store as-is with redis::cmd
        
        // Execute XADD command
        let stream_id: String = cmd("XADD")
            .arg(stream_key)
            .arg(if max_len.is_some() { "MAXLEN" } else { "" })
            .arg(if max_len.is_some() { "~" } else { "" })
            .arg(if let Some(len) = max_len { len.to_string() } else { String::new() })
            .arg("*")
            .arg("message_id")
            .arg(message_id)
            .arg("payload")
            .arg(message_bytes) // redis crate should handle Vec<u8>
            .query_async(&mut self.client)
            .await
            .context("Failed to XADD message to stream")?;
        
        Ok(stream_id)
    }

    /// Create consumer group for stream
    /// 
    /// XGROUP CREATE stream_key group_name start_id [MKSTREAM]
    /// 
    /// MKSTREAM creates the stream if it doesn't exist
    /// start_id "0" means start from the beginning
    pub async fn create_consumer_group(
        &mut self,
        stream_key: &str,
        group_name: &str,
        start_id: &str, // Usually "0" for new streams
    ) -> Result<()> {
        // Try to create consumer group
        // BUSYGROUP error is fine (group already exists)
        let result: Result<(), redis::RedisError> = cmd("XGROUP")
            .arg("CREATE")
            .arg(stream_key)
            .arg(group_name)
            .arg(start_id)
            .arg("MKSTREAM") // Create stream if doesn't exist
            .query_async(&mut self.client)
            .await;
        
        match result {
            Ok(()) => Ok(()),
            Err(e) => {
                let err_str = e.to_string();
                if err_str.contains("BUSYGROUP") {
                    // Group already exists, this is fine
                    tracing::debug!(
                        stream_key = %stream_key,
                        group_name = %group_name,
                        "Consumer group already exists"
                    );
                    Ok(())
                } else {
                    Err(anyhow::anyhow!("Failed to create consumer group: {}", e))
                }
            }
        }
    }

    /// Read messages from stream using XREADGROUP with blocking
    /// 
    /// XREADGROUP GROUP group_name consumer_name BLOCK timeout COUNT count STREAMS stream_key >
    /// 
    /// ">" means: read only new messages (not yet delivered to this consumer)
    /// Blocking timeout in milliseconds
    /// Returns empty vec if no messages (after timeout)
    pub async fn read_from_delivery_stream(
        &mut self,
        stream_key: &str,
        group_name: &str,
        consumer_name: &str,
        block_ms: u64,
        count: usize,
    ) -> Result<Vec<StreamMessage>> {
        // XREADGROUP GROUP group_name consumer_name BLOCK block_ms COUNT count STREAMS stream_key >
        let result: Result<Vec<(String, Vec<(String, Vec<(String, Vec<u8>)>)>)>, redis::RedisError>> = 
            cmd("XREADGROUP")
                .arg("GROUP")
                .arg(group_name)
                .arg(consumer_name)
                .arg("BLOCK")
                .arg(block_ms as i64)
                .arg("COUNT")
                .arg(count as i64)
                .arg("STREAMS")
                .arg(stream_key)
                .arg(">") // Read new messages
                .query_async(&mut self.client)
                .await;
        
        match result {
            Ok(mut streams) => {
                if streams.is_empty() {
                    return Ok(vec![]);
                }
                
                // Parse result: [(stream_key, [(message_id, [(field, value), ...]), ...])]
                let messages = streams
                    .into_iter()
                    .flat_map(|(_, messages)| {
                        messages.into_iter().map(|(id, fields)| {
                            let field_map: HashMap<String, Vec<u8>> = fields
                                .into_iter()
                                .collect();
                            
                            StreamMessage {
                                id,
                                fields: field_map,
                            }
                        })
                    })
                    .collect();
                
                Ok(messages)
            }
            Err(redis::RedisError::from((redis::ErrorKind::IoError, _))) if block_ms > 0 => {
                // Timeout on blocking read - this is normal, return empty
                Ok(vec![])
            }
            Err(e) => Err(anyhow::anyhow!("Failed to read from stream: {}", e)),
        }
    }

    /// Acknowledge processed messages
    /// 
    /// XACK stream_key group_name message_id [message_id ...]
    /// 
    /// Can acknowledge multiple messages at once
    pub async fn ack_delivery_message(
        &mut self,
        stream_key: &str,
        group_name: &str,
        message_ids: &[&str],
    ) -> Result<usize> {
        if message_ids.is_empty() {
            return Ok(0);
        }
        
        let mut cmd_builder = cmd("XACK")
            .arg(stream_key)
            .arg(group_name);
        
        for id in message_ids {
            cmd_builder = cmd_builder.arg(id);
        }
        
        let acked_count: i64 = cmd_builder
            .query_async(&mut self.client)
            .await
            .context("Failed to ACK messages")?;
        
        Ok(acked_count as usize)
    }

    /// Migrate messages from offline stream to delivery stream
    /// 
    /// Reads all messages from offline stream and adds them to delivery stream
    pub async fn migrate_offline_stream(
        &mut self,
        offline_stream_key: &str,
        delivery_stream_key: &str,
        max_len: Option<usize>,
    ) -> Result<usize> {
        // Read all messages from offline stream (non-blocking)
        let result: Result<Vec<(String, Vec<(String, Vec<(String, Vec<u8>)>)>)>, redis::RedisError>> =
            cmd("XREAD")
                .arg("COUNT")
                .arg(10000) // Read up to 10k messages
                .arg("STREAMS")
                .arg(offline_stream_key)
                .arg("0") // Start from beginning
                .query_async(&mut self.client)
                .await;
        
        let messages = match result {
            Ok(mut streams) => {
                if streams.is_empty() {
                    return Ok(0);
                }
                streams.into_iter()
                    .flat_map(|(_, msgs)| msgs)
                    .collect::<Vec<_>>()
            }
            Err(redis::RedisError::from((redis::ErrorKind::TypeError, _))) => {
                // Stream doesn't exist or is empty
                return Ok(0);
            }
            Err(e) => return Err(anyhow::anyhow!("Failed to read offline stream: {}", e)),
        };
        
        if messages.is_empty() {
            return Ok(0);
        }
        
        // Add all messages to delivery stream
        let mut migrated = 0;
        for (_, fields) in messages {
            // Extract message_id and payload from fields
            let field_map: HashMap<String, Vec<u8>> = fields.into_iter().collect();
            let message_id = field_map.get("message_id")
                .and_then(|b| String::from_utf8(b.clone()).ok())
                .context("Failed to extract message_id from stream message")?;
            let payload = field_map.get("payload")
                .context("Failed to extract payload from stream message")?;
            
            // Add to delivery stream
            self.push_to_delivery_stream(
                delivery_stream_key,
                &message_id,
                payload,
                max_len,
            ).await?;
            
            migrated += 1;
        }
        
        // Delete offline stream after migration
        let _: () = cmd("DEL")
            .arg(offline_stream_key)
            .query_async(&mut self.client)
            .await
            .context("Failed to delete offline stream")?;
        
        Ok(migrated)
    }

    /// Check pending messages for consumer group
    /// 
    /// Useful for processing messages that were read but not ACKed (e.g., after crash)
    pub async fn get_pending_messages(
        &mut self,
        stream_key: &str,
        group_name: &str,
        count: usize,
    ) -> Result<Vec<StreamMessage>> {
        // XPENDING stream_key group_name [start] [end] [count] [consumer_name]
        // Get pending message IDs
        let pending_info: (String, String, i64, Vec<(String, String, i64, i64)>) = 
            cmd("XPENDING")
                .arg(stream_key)
                .arg(group_name)
                .arg("-") // Start
                .arg("+") // End
                .arg(count as i64)
                .query_async(&mut self.client)
                .await
                .context("Failed to get pending messages")?;
        
        let pending_ids: Vec<String> = pending_info.3
            .into_iter()
            .map(|(id, _, _, _)| id)
            .collect();
        
        if pending_ids.is_empty() {
            return Ok(vec![]);
        }
        
        // Claim and read pending messages
        // XCLAIM stream_key group_name consumer_name min_idle_time message_id [message_id ...]
        // For simplicity, we'll use XREADGROUP with "0" to read pending messages
        // Actually, we should use XAUTOCLAIM or XCLAIM for pending messages
        
        // Read pending messages using XREADGROUP with "0" (pending messages)
        let result: Result<Vec<(String, Vec<(String, Vec<(String, Vec<u8>)>)>)>, redis::RedisError>> =
            cmd("XREADGROUP")
                .arg("GROUP")
                .arg(group_name)
                .arg(&format!("pending-reader-{}", chrono::Utc::now().timestamp()))
                .arg("COUNT")
                .arg(count as i64)
                .arg("STREAMS")
                .arg(stream_key)
                .arg("0") // Read pending messages
                .query_async(&mut self.client)
                .await;
        
        match result {
            Ok(mut streams) => {
                if streams.is_empty() {
                    return Ok(vec![]);
                }
                
                let messages = streams
                    .into_iter()
                    .flat_map(|(_, messages)| {
                        messages.into_iter().map(|(id, fields)| {
                            let field_map: HashMap<String, Vec<u8>> = fields
                                .into_iter()
                                .collect();
                            
                            StreamMessage {
                                id,
                                fields: field_map,
                            }
                        })
                    })
                    .collect();
                
                Ok(messages)
            }
            Err(e) => Err(anyhow::anyhow!("Failed to read pending messages: {}", e)),
        }
    }
}