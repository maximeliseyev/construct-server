# fly.worker.toml app configuration file for Construct Delivery Worker
#
# This is a background worker that processes message delivery:
# - Kafka consumer: Reads messages from construct-messages topic
# - Redis Pub/Sub: Listens for user online notifications
# - Offline message delivery: Moves messages from Kafka to online users
# - Delivery ACK processing: Consumes delivery ACK events from Kafka
#
# Architecture (Phase 2-4):
# - Dual-read mode: Reads from BOTH Kafka and Redis offline queues
# - Kafka consumer group: cnstrct-dlvr-wrkrs (horizontal scaling)
# - Partitioned by user_id for load balancing
#
# Architecture (Phase 5+):
# - Kafka-only mode: Single source of truth
# - Kafka offset rewind for offline message delivery
#
# Deploy with: make deploy-worker
# Or: fly deploy --config ops/fly.worker.toml --app construct-delivery-worker
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.

app = 'construct-delivery-worker'
primary_region = 'ams'

[build]
  # Dockerfile path is specified via --dockerfile flag in Makefile

[processes]
  app = "delivery-worker"

[env]
  # Rust logging level (reduced noise in production)
  RUST_LOG = "info,sqlx=warn,construct_server=info"
  
  # Database connection pool settings (if worker uses DB)
  DB_MAX_CONNECTIONS = "5"
  DB_ACQUIRE_TIMEOUT_SECS = "30"
  DB_IDLE_TIMEOUT_SECS = "600"

  # Delivery worker config
  DELIVERY_POLL_INTERVAL_MS = "10000"
  HEARTBEAT_INTERVAL_SECS = "90"
  SERVER_REGISTRY_TTL_SECS = "270"

  # Redis prefixes
  ONLINE_CHANNEL = "user_online_notifications:"
  DELIVERY_QUEUE_PREFIX = "delivery_queue:"
  OFFLINE_QUEUE_PREFIX = "offline:"

  # Message TTL
  MESSAGE_TTL_DAYS = "7"

# No HTTP service for worker (it's a background process)
# Workers communicate via Redis Pub/Sub and Kafka

[[vm]]
  memory = '512mb'
  cpus = 1

# Worker should always be running (not auto-stop)
[deploy]
  strategy = "rolling"
  max_unavailable = 1

# Auto-scaling based on Kafka consumer lag
[autoscaling]
  min_instances = 2
  max_instances = 10

  # Scale based on CPU (when processing heavy load)
  [[autoscaling.metrics]]
    type = "cpu"
    target = 70

# Secrets to set via: make secrets-worker
# Or: bash ops/setup-fly-secrets.sh
# Required secrets:
# - DATABASE_URL (PostgreSQL - for user lookup)
# - REDIS_URL (Upstash Redis - for Pub/Sub, server registry)
# - JWT_SECRET (required by Config::from_env)
# - JWT_ISSUER (required by Config::from_env)
# - LOG_HASH_SALT (for hashing user IDs in logs)
# - KAFKA_ENABLED=true
# - KAFKA_BROKERS (Confluent Cloud)
# - KAFKA_TOPIC
# - KAFKA_CONSUMER_GROUP=cnstrct-dlvr-wrkrs
# - KAFKA_SSL_ENABLED=true
# - KAFKA_SASL_MECHANISM=PLAIN
# - KAFKA_SASL_USERNAME
# - KAFKA_SASL_PASSWORD
# - DELIVERY_ACK_MODE=kafka
# - DELIVERY_SECRET_KEY
